#!/usr/bin/python
# Aggregates the word frequency data from the 2016 republican and democratic
# debates.

import bs4
import json
import re
import requests

BASE_URL = "http://api.nytimes.com/svc/search/v2/articlesearch.json"

def get_word_frequency(text, stopwords):
    words = re.sub("[^\w ]", " ", text).lower().split()
    frequency = {}
    for word in words:
        if word in stopwords:
            continue
        if word in frequency:
            frequency[word] += 1
        else:
            frequency[word] = 1

    # Words are considered negligible if they occur less than 15 times.
    for word in frequency.keys():
        if frequency[word] < 15:
            del frequency[word]
    return frequency

def main():
    CANDIDATE_KEYWORDS = [
        "TRUMP",
        "RUBIO",
        "CRUZ",
        "KASICH",
        "CARSON",
        "PAUL",
        "HUCKABEE",
        "OMALLEY",
        "CLINTON",
        "SANDERS",
        "BUSH"
    ]

    candidate_speech = {}

    # Reads in the list of articles
    with open("links.txt") as link_file:
        article_links = link_file.read().strip().split()

    with open("stopwords.txt") as stopwords_file:
        stopwords = stopwords_file.read().strip().split()

    debate = ""

    for link in article_links:
        # Gets the HTML content of the page to filter out the text
        response = requests.get(link)
        soup = bs4.BeautifulSoup(response.text, "html.parser")
        text = soup.get_text().split("\n")

        # The debate itself is in contiguous blocks that we can assume to be
        # at least 5000 characters in length.
        debate_text = filter(lambda section: any(
            [candidate in section for candidate in CANDIDATE_KEYWORDS]), text)
        debate_text = " ".join(debate_text)
        debate_text = re.sub("\([A-Z ]+\)|[^\w: .,?!]", "", debate_text)
        debate += debate_text

    print "Debates aggregated..."

    # After we get the contents of all the debates in one big string, we
    # parse that string and filter out segments based on who said that
    # segment. We create a dictionary of the form
    # { SPEAKER: EVERYTHING_THEY_SAID; SPEAKER2: EVERYTHING_THEY_SAID }
    match = re.search("[A-Z]+:", debate)
    while match is not None:
        debate = debate[match.end():]
        speaker = match.group()[:-1]
        match = re.search("[A-Z]+:", debate)
        if match:
            speaker_words = debate[:match.start()]
        else:
            speaker_words = debate

        if speaker in candidate_speech:
            candidate_speech[speaker] += speaker_words
        else:
            candidate_speech[speaker] = speaker_words

    print "Speakers aggregated..."

    # The article has a spelling error!
    if "TRUMP" in candidate_speech:
        candidate_speech["TRUMP"] += candidate_speech["TRUMO"]
        del candidate_speech["TRUMO"]
    if "SANDERS" in candidate_speech:
        candidate_speech["SANDERS"] += candidate_speech["SANDERFS"]
        candidate_speech["SANDERS"] += candidate_speech["OKSANDERS"]
        del candidate_speech["SANDERFS"]
        del candidate_speech["OKSANDERS"]
    if "KASICH" in candidate_speech:
        candidate_speech["KASICH"] += candidate_speech["KAISCH"]
        del candidate_speech["KAISCH"]

    for key in candidate_speech.keys():
        if key not in CANDIDATE_KEYWORDS:
            del candidate_speech[key]

    # After aggregating the total speech of every speaker, we parse what they
    # said to count the frequency of each word.
    for key, value in candidate_speech.iteritems():
        candidate_speech[key] = get_word_frequency(candidate_speech[key],
                                                   stopwords)

    # Sort dem words
    for candidate in candidate_speech.keys():
        words = []
        word_frequencies = candidate_speech[candidate]
        for word in sorted(word_frequencies, key=word_frequencies.get,
                           reverse=True):
            words.append([word, word_frequencies[word]])
        candidate_speech[candidate] = words

    # This is then dumped to a js file.
    with open("data.js", "w") as data_file:
        data_file.write(
        """
        /**
         * Autogenerated, do not edit!
         */
        var wordFrequencies = %s;
        """ %
        json.dumps(candidate_speech))

if __name__ == "__main__":
    main()
